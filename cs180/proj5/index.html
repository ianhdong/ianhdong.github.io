<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/cs180/css/styles.css">
    <script src="/cs180/js/hamburger.js" defer></script>


    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <title>CS 180 Project 5: Diffusion Models</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>

</head>


<body>
    <div class="content">

        <h1 align="middle">CS 180: Intro to Computer Vision and Computational Photography, Fall 2024</h1>
        <h1 align="middle"><a href="#5a">Project 5A: Fun with Diffusion Models</a>
        </h1>
        <h2 align="middle">Ian Dong</h2>

        <br><br>



        <div class="bounding-box">

            <h2 align="middle" id="5a">Overview</h2>

            In this first part of the project, I played around with the DeepFloyd IF diffusion model, implemented
            diffusion sampling loops, and then used them to create inpainted and optical illusions. I learned a lot
            about diffusion models and how they can be used to create cool effects on images.
            <br><br>
        </div>

        <br><br>

        <h2 align="middle">Section 0: Setup</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Using the DeepFloyd IF Diffusion Model
            </h3>
            <p>
                For this part, I instantiated DeepFloyd's <code class="highlighter-rouge">stage_1</code> and <code
                    class="highlighter-rouge">stage_2</code> and passed in the following text prompts: <i>an oil
                    painting of a snowy mountain village, a man wearing a hat,</i> and <i> a rocket ship</i>. I set the
                seed to be 180 for all parts. Then, I varied the inference steps to generate the following images:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/setup/stage_1_mountain_20.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_mountain_20.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (20 Stepss)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_1_mountain_50.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (50 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_mountain_50.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (50 Steps)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/setup/stage_1_man_20.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_man_20.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_1_man_50.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (50 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_man_50.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (50 Steps)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/setup/stage_1_rocket_50.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_rocket_50.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_1_rocket_20.png" align="middle" width="400px" />
                        <figcaption>OStage 1 (50 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_rocket_20.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (50 Steps)</figcaption>
                    </td>

                </tr>
            </table>

            <p>
                The quality of the images becomes much more clearer after stage 2. It seems that all of the images fit
                the given prompt pretty well. For each of the prompts, as we increase the number of inference steps it
                seems that the images become much more detailed and fancy. For example in the man iwth the hat it looks
                more realistic and the snow has a lot more details with the shading.
            </p>
        </div>

        <br>
        <br>

        <h2 align="middle">Section I: Sampling Loops</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Implementing the Forward Process
            </h3>
            <p>
                In this section, I implemented the forward process of the diffusion model to gradually add more noise to
                a clean image. The forward process is defined by:

                $$ q(x_{t} | x_{0}) = \mathcal{N}(X_{t}, \sqrt{\overline{\alpha}}x_{0}, (1 -
                \overline{\alpha}_{t})\mathbf{I})$$ which is equivalent to:

                $$x_{t} = \sqrt{\overline{\alpha}_{t}}x_{0} + \sqrt{1 - \overline{\alpha}_{t}} \epsilon \quad
                \text{where } \epsilon \sim \mathcal{N}(0, 1).$$ I sampled from a Gaussian distribution to add more
                noise to the original image. Here are the results:
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Campanile</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_250.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_500.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_750.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 750</figcaption>
                    </td>

                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Classical Denoising
            </h3>
            <p>
                Then, I applied <i>Gaussian blur filtering</i> over the above images in an attempt to reduce the noise. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_250.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_500.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_750.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 750</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_250.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_500.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_750.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoise Level = 750</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                One-Step Denoising
            </h3>
            <p>
                For the next step, I implemented the one-step denoising process by using the <code class="highlighter-rouge">stage_1.unet</code> to estimate the Gaussian noise and subtract it from the noisy images. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_250.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_500.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_750.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 750</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/estimate_250.png" align="middle" width="400px" />
                        <figcaption>Estimate of Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/estimate_500.png" align="middle" width="400px" />
                        <figcaption>Estimate of Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/estimate_750.png" align="middle" width="400px" />
                        <figcaption>Estimate of Original</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Iterative Denoising
            </h3>
            <p>
                Finally, I implemented iterative denoising to further reduce the noise and get a better estimate. I used strided timesteps to speed things up and skip steps. The formula I used was:

                $$x_{t'} = \frac{\sqrt{\bar\alpha_{t'}}\beta_t}{1 - \bar\alpha_t} x_0 +
                \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t'})}{1 - \bar\alpha_t} x_t +
                v_\sigma$$

                This helps to move from a noiser image to a cleaner image similar to finding a linear interpolation between both of them. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_690.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 690</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_570.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 540</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_420.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 390</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_270.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 240 </figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_120.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 90</figcaption>
                    </td>
                </tr>
            </table>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/final_iterative.png" align="middle" width="400px" />
                        <figcaption>Iteratively Denoised</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/one_step.png" align="middle" width="400px" />
                        <figcaption>One Step Denoised</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_denoised.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoised </figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Diffusion Model Sampling
            </h3>
            <p>
                In this section, I passed in random noise and used the <code class="highlighter-rouge">iterative_denoise</code> to effectively defnoise pure noise. This allows me to generate images from scratch by setting <code class="highlighter-rouge">i_start = 0</code>. Here are the results with the prompt = <i>a high quality photo</i>:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/GeneratedImages/image1.png" align="middle" width="400px" />
                        <figcaption>Image 1</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image2.png" align="middle" width="400px" />
                        <figcaption>Image 2</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image3.png" align="middle" width="400px" />
                        <figcaption>Image 3</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image4.png" align="middle" width="400px" />
                        <figcaption>Image 4</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image5.png" align="middle" width="400px" />
                        <figcaption>Image 5</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>

        <h1 align="middle"><a href="#4b">Project 4B:Feature Matching for Auto-Stitching</a>
        </h1>

        <div class="bounding-box">

            <h2 align="middle" id="4b">Overview</h2>

            The second part of the project will automatically stitch together images into a mosaic by finding and
            matching
            feature descriptors. I used Harris corner detection to find the corners of the images and then used Adaptive
            Non-Maximal Suppression to get a better spatial distribution of the points. Finally, I used nearest neighbor
            to
            match up the image patches and then used RANSAC to find the homography matrix that best fits the points. I
            then
            used the homography matrix to warp the images and blend them together to create a seamless mosaic.
            <br><br>
        </div>

        <br>
        <br>

        <h2 align="middle">Section I: Detecting Corner Features in an Image</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Harris Interest Point Detector
            </h3>
            <p>
                I used the <code class="highlighter-rouge">get_harris_corners</code> starter code to get the Harris
                points and
                identify corners within an image. This will be helpful in finding the feature points that we can use to
                match up
                the images. The Harris corner detection algorithm calculates the intensity gradients at a certain
                location which
                represent the rate of change in pixel intensities along the $x$ and $y$ directions and thus the edges
                and
                corners that have sharp intensity changes. I also filtered out the corners by setting a threshold on the
                corner
                response value and overlaid them on the images. Here are the results:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/4a/sink/sink_left.jpg" align="middle" width="400px" />
                        <figcaption>Sink Left (Original)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/sink/sink_left.png" align="middle" width="400px" />
                        <figcaption>Sink Left (Harris)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4a/sink/sink_right.jpg" align="middle" width="400px" />
                        <figcaption>Sink Right (Original)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/sink/sink_right.png" align="middle" width="400px" />
                        <figcaption>Sink Right (Harris)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4a/outside/outside_left.jpg" align="middle" width="400px" />
                        <figcaption>Outside Left (Original)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/outside/outside_left.png" align="middle" width="400px" />
                        <figcaption>Outside Left (Harris)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4a/outside/outside_right.jpg" align="middle" width="400px" />
                        <figcaption>Outside Right (Original)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/outside/outside_right.png" align="middle" width="400px" />
                        <figcaption>Outside Right (Harris)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4a/campanile/campanile_left.jpg" align="middle" width="400px" />
                        <figcaption>Campanile Left (Original)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/campanile/campanile_left.png" align="middle" width="400px" />
                        <figcaption>Campanile Left (Harris)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4a/campanile/campanile_right.jpg" align="middle" width="400px" />
                        <figcaption>Campanile Right (Original)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/campanile/campanile_right.png" align="middle" width="400px" />
                        <figcaption>Campanile Right (Harris)</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>

        <h2 align="middle">Section II: Adaptive Non-Maximal Suppression</h2>

        <div class="bounding-box">
            <h3 align="middle">
                ANMS Algorithm
            </h3>
            <p>
                As shown above, there were a lot of different corner points. I wanted to distribute the points more
                evenly
                around the images. First, I found the distances between each pair of points from the two different
                images. Then,
                I sorted by the corner response value. For each point in the first image, I calculated the suppression
                radius
                using the following formula:

                $$ r_i = \min_j |x_i - x_j|, \text{ s.t. } f(x_i) < c_{\text{robust}} \cdot f(x_j)$$ Finally, I sorted
                    the points by their suppression radius and selected the $n$ points with the largest radius. This way
                    I could get a better spatial distribution of the points. Here are the results: </p>
                    <div align="middle"></div>
                    <table>
                        <tr align="center">
                            <td>
                                <img src="./Images/4b/sink/sink_left_anms.png" align="middle" width="400px" />
                                <figcaption>Sink Left (ANMS)</figcaption>
                            </td>
                            <td>
                                <img src="./Images/4b/sink/sink_right_anms.png" align="middle" width="400px" />
                                <figcaption>Sink Right (ANMS)</figcaption>
                            </td>
                        </tr>
                        <tr align="center">
                            <td>
                                <img src="./Images/4b/outside/outside_left_anms.png" align="middle" width="400px" />
                                <figcaption>Outside Left (ANMS)</figcaption>
                            </td>
                            <td>
                                <img src="./Images/4b/outside/outside_right_anms.png" align="middle" width="400px" />
                                <figcaption>Outside Right (ANMS)</figcaption>
                            </td>
                        </tr>
                        <tr align="center">
                            <td>
                                <img src="./Images/4b/campanile/campanile_left_anms.png" align="middle" width="400px" />
                                <figcaption>Campanile Left (ANMS)</figcaption>
                            </td>
                            <td>
                                <img src="./Images/4b/campanile/campanile_right_anms.png" align="middle"
                                    width="400px" />
                                <figcaption>Campanile Right (ANMS)</figcaption>
                            </td>
                        </tr>
                    </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section III: Extracting Feature Descriptors</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Extracting Feature Descriptors
            </h3>
            <p>
                For each of the ANMS points from before, I took a 40 by 40 patch centered at the point and then
                downsampled into
                8 by 8 mini-patch. Afterwards, I normalized the mini-patch (0 mean and unit variance) and then flattened
                into a
                vector. Here are the results:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/feature-descriptor/fd1.png" align="middle" width="400px" />
                        <figcaption>40 x 40 Patch</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/feature-descriptor/fd1_mini.png" align="middle" width="400px" />
                        <figcaption>8 x 8 Mini-Patch</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/feature-descriptor/fd2.png" align="middle" width="400px" />
                        <figcaption>40 x 40 Patch</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/feature-descriptor/fd2_mini.png" align="middle" width="400px" />
                        <figcaption>8 x 8 Mini-Patch</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section IV: Matching Feature Descriptors</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Matching Feature Descriptors
            </h3>
            <p>
                With the flattened feature descriptors, I would be able to find the best matches between the images. I
                followed
                along with the algorithm in this <a
                    href="https://inst.eecs.berkeley.edu/~cs180/fa24/hw/proj4/Papers/MOPS.pdf">research paper</a>.
                First, I used
                the provided <code class="highlighter-rouge">dist2</code> function to calculate the SSD between each
                pair of
                points from image 1 and image 2. Then, I found the Lowe's score for each point in image 1 which is the
                ratio of
                1-NN distance to 2-NN distance. If the Lowe's score we below a certain a threshold, I added the point
                and its
                1-NN to the matches. Finally, I plotted each point in image 1 with its corresponding 1-NN in image 2.
                Here are the results:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/sink/sink_matching_points.png" align="middle" width="400px" />
                        <figcaption>Sink Matching Feature Descriptors</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/outside/outside_matching_points.png" align="middle" width="400px" />
                        <figcaption>Outside Matching Feature Descriptors</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/campanile/campanile_matching_points.png" align="middle" width="400px" />
                        <figcaption>Campanile Matching Feature Descriptors</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section V: Running RANSAC</h2>

        <div class="bounding-box">
            <h3 align="middle">
                RANSAC
            </h3>
            <p>
                As shown above in the matching feature descriptors, there were some points that were not matched
                correctly. I
                used the RANSAC algorithm to further improve the number of matches and find the best ones to compute the
                homography matrix. These are the following steps I took:

            <ol>
                <li>Randomly select 4 pairs of points from the matches.</li>
                <li>Compute the homography matrix using the 4 pairs of points.</li>
                <li>Warp the points from image 1 to image 2 using the homography matrix.</li>
                <li>Calculate the SSD between the warped points and the points in image 2.</li>
                <li>Count the number of inliers where the SSD is below a certain threshold.</li>
                <li>Repeat steps 1-5 for a certain number of iterations.</li>
                <li>Recompute the approximate homography using the set of the largest inliers.</li>
            </ol>

            I plotted the selected inliers onto their respective images and the warped left image into the right image's
            perspective. Here are the results:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/sink/sink_left_subset.png" align="middle" width="400px" />
                        <figcaption>Sink Left Subset</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/sink/sink_right_subset.png" align="middle" width="400px" />
                        <figcaption>Sink Right Subset</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/sink/sink_left_warped_auto_stitched.jpg" align="middle" width="400px" />
                        <figcaption>Sink Left (Warped)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/outside/outside_left_subset.png" align="middle" width="400px" />
                        <figcaption>Outside Left Subset</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/outside/outside_right_subset.png" align="middle" width="400px" />
                        <figcaption>Outside Right Subset</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/outside/outside_left_warped_auto_stitched.jpg" align="middle"
                            width="400px" />
                        <figcaption>Outside Left (Warped)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4b/campanile/campanile_left_subset.png" align="middle" width="400px" />
                        <figcaption>Campanile Left Subset</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/campanile/campanile_right_subset.png" align="middle" width="400px" />
                        <figcaption>Campanile Right Subset</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/campanile/campanile_left_warped_auto_stitched.jpg" align="middle"
                            width="400px" />
                        <figcaption>Campanile Left (Warped)</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <br>
        <br>

        <h2 align="middle">Section VI: Producing the Mosaic and Comparisons</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Mosaic Comparison
            </h3>
            <p>
                Using the above 4-point RANSAC algorithm, I auto-stitched together the images to create a seamless
                mosaic
                without predefining the correspondences. I also compared them to Part A's mosaics where I manually
                created the
                correspondences. As shown below, the auto-stitched mosaics found better homographies as there are fewer
                artifacts and blurriness compared to the manual defined mosaics. Here are the results:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/4a/sink/sink_mosaic_final.jpg" align="middle" width="400px" />
                        <figcaption>Sink Mosaic (Predefined Points)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/sink/sink_mosaic_auto_stitched.jpg" align="middle" width="400px" />
                        <figcaption>Sink Mosaic (Auto-Stitched Points)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4a/outside/outside_mosaic_final.jpg" align="middle" width="400px" />
                        <figcaption>Outside Mosaic (Predefined Points)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/outside/outside_mosaic_auto_stitched.jpg" align="middle" width="400px" />
                        <figcaption>Outside Mosaic (Auto-Stitched Points)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/4a/campanile/campanile_mosaic_final.jpg" align="middle" width="400px" />
                        <figcaption>Campanile Mosaic (Predefined Points)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/4b/campanile/campanile_mosaic_auto_stitched.jpg" align="middle"
                            width="400px" />
                        <figcaption>Campanile Mosaic (Auto-Stitched Points)</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>

        <h2 align="middle">Section VII: Conclusion</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Learnings
            </h3>
            <p>
                I learned a lot about finetuning and filtering out the Harris corners especially to get a better spatial
                distribution on the images. Throughout this process, I made sure to note down what order my points in
                whether as
                (row, col) or (y, x). This way when I'm plotting and calculating the homography matrix I would get the
                correct
                results. The coolest takeaway was finding the best matches to automatically stitch together the images.
            </p>
        </div>

</body>

</html>