<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/cs180/css/styles.css">
    <script src="/cs180/js/hamburger.js" defer></script>


    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <title>CS 180 Project 5: Diffusion Models</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>

</head>


<body>
    <div class="content">

        <h1 align="middle">CS 180: Intro to Computer Vision and Computational Photography, Fall 2024</h1>
        <h1 align="middle"><a href="#5a">Project 5A: Fun with Diffusion Models</a>
        </h1>
        <h2 align="middle">Ian Dong</h2>

        <br><br>



        <div class="bounding-box">

            <h2 align="middle" id="5a">Overview</h2>

            In this first part of the project, I played around with the DeepFloyd IF diffusion model, implemented
            diffusion sampling loops, and then used them to create inpainted and optical illusions. I learned a lot
            about diffusion models and how they can be used to create cool effects on images.
            <br><br>
        </div>

        <br><br>

        <h2 align="middle">Section 0: Setup</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Using the DeepFloyd IF Diffusion Model
            </h3>
            <p>
                For this part, I instantiated DeepFloyd's <code class="highlighter-rouge">stage_1</code> and <code
                    class="highlighter-rouge">stage_2</code> and passed in the following text prompts: <i>an oil
                    painting of a snowy mountain village, a man wearing a hat,</i> and <i> a rocket ship</i>. I set the
                seed to be 180 for all parts. Then, I varied the inference steps to generate the following images:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/setup/stage_1_mountain_20.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_mountain_20.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (20 Stepss)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_1_mountain_50.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (50 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_mountain_50.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (50 Steps)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/setup/stage_1_man_20.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_man_20.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_1_man_50.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (50 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_man_50.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (50 Steps)</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/setup/stage_1_rocket_50.png" align="middle" width="400px" />
                        <figcaption>Stage 1 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_rocket_50.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (20 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_1_rocket_20.png" align="middle" width="400px" />
                        <figcaption>OStage 1 (50 Steps)</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/setup/stage_2_rocket_20.png" align="middle" width="400px" />
                        <figcaption>Stage 2 (50 Steps)</figcaption>
                    </td>

                </tr>
            </table>

            <p>
                The quality of the images becomes much more clearer after stage 2. It seems that all of the images fit
                the given prompt pretty well. For each of the prompts, as we increase the number of inference steps it
                seems that the images become much more detailed and fancy. For example in the man with the hat it looks
                more realistic and the snow has a lot more details with the shading.
            </p>
        </div>

        <br>
        <br>

        <h2 align="middle">Section I: Implementing the Forward Process</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Implementing the Forward Process
            </h3>
            <p>
                In this section, I implemented the forward process of the diffusion model to gradually add more noise to
                a clean image. The forward process is defined by:

                $$ q(x_{t} | x_{0}) = \mathcal{N}(X_{t}, \sqrt{\overline{\alpha}}x_{0}, (1 -
                \overline{\alpha}_{t})\mathbf{I})$$ which is equivalent to:

                $$x_{t} = \sqrt{\overline{\alpha}_{t}}x_{0} + \sqrt{1 - \overline{\alpha}_{t}} \epsilon \quad
                \text{where } \epsilon \sim \mathcal{N}(0, 1).$$ I sampled from a Gaussian distribution to add more
                noise to the original image. Here are the results:
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Campanile</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_250.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_500.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_750.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 750</figcaption>
                    </td>

                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section II: Classical Denoising</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Classical Denoising
            </h3>
            <p>
                Then, I applied <i>Gaussian blur filtering</i> over the above images in an attempt to reduce the noise.
                Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_250.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_500.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_750.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 750</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_250.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_500.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_750.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoise Level = 750</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section III: One-Step Denoising</h2>
        <div class="bounding-box">
            <h3 align="middle">
                One-Step Denoising
            </h3>
            <p>
                For the next step, I implemented the one-step denoising process by using the <code
                    class="highlighter-rouge">stage_1.unet</code> to estimate the Gaussian noise and subtract it from
                the noisy images. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_250.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 250</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_500.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 500</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/noisy_image_750.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 750</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/estimate_250.png" align="middle" width="400px" />
                        <figcaption>Estimate of Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/estimate_500.png" align="middle" width="400px" />
                        <figcaption>Estimate of Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/estimate_750.png" align="middle" width="400px" />
                        <figcaption>Estimate of Original</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section IV: Iterative Denoising</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Iterative Denoising
            </h3>
            <p>
                Finally, I implemented iterative denoising to further reduce the noise and get a better estimate. I used
                strided timesteps to speed things up and skip steps. The formula I used was:

                $$x_{t'} = \frac{\sqrt{\bar\alpha_{t'}}\beta_t}{1 - \bar\alpha_t} x_0 +
                \frac{\sqrt{\alpha_t}(1 - \bar\alpha_{t'})}{1 - \bar\alpha_t} x_t +
                v_\sigma$$

                This helps to move from a noiser image to a cleaner image similar to finding a linear interpolation
                between both of them. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_690.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 690</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_570.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 540</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_420.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 390</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_270.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 240 </figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/iterative_120.png" align="middle" width="400px" />
                        <figcaption>Noise Level = 90</figcaption>
                    </td>
                </tr>
            </table>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/final_iterative.png" align="middle" width="400px" />
                        <figcaption>Iteratively Denoised</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/one_step.png" align="middle" width="400px" />
                        <figcaption>One Step Denoised</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/gaussian_denoised.png" align="middle" width="400px" />
                        <figcaption>Gaussian Denoised </figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section V: Diffusion Model Sampling</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Diffusion Model Sampling
            </h3>
            <p>
                In this section, I passed in random noise and used the <code
                    class="highlighter-rouge">iterative_denoise</code> to effectively defnoise pure noise. This allows
                me to generate images from scratch by setting <code class="highlighter-rouge">i_start = 0</code>. Here
                are the results with the prompt = <i>a high quality photo</i>:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/GeneratedImages/image1.png" align="middle" width="400px" />
                        <figcaption>Image 1</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image2.png" align="middle" width="400px" />
                        <figcaption>Image 2</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image3.png" align="middle" width="400px" />
                        <figcaption>Image 3</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image4.png" align="middle" width="400px" />
                        <figcaption>Image 4</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/image5.png" align="middle" width="400px" />
                        <figcaption>Image 5</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section VI: Classifier Free Guidance</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Classifier Free Guidance
            </h3>
            <p>
                In the previous section, the generated images did not have great quality. I used classifier free
                guidance to greatly improve image quality. First, I computed both a noise estimate on a text prompt and
                an unconditional noise estimate. I let the new noise estimate be:
                $$ \epsilon = \epsilon_u + \gamma(\epsilon_c - \epsilon_u)$$
                where $\gamma$ helps to control the strength of CFG. Here are the results with the prompt = <i>a high
                    quality photo</i>:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/GeneratedImages/cfg_image1.png" align="middle" width="400px" />
                        <figcaption>CFG Image 1</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/cfg_image2.png" align="middle" width="400px" />
                        <figcaption>CFG Image 2</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/cfg_image3.png" align="middle" width="400px" />
                        <figcaption>CFG Image 3</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/cfg_image4.png" align="middle" width="400px" />
                        <figcaption>CFG Image 4</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/GeneratedImages/cfg_image5.png" align="middle" width="400px" />
                        <figcaption>CFG Image 5</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section VII: Image to Image Translation</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Image to Image Translation
            </h3>
            <p>
                In the previous sections, we can see that as we add noise we can make modifications to existing images.
                The greater the noise the more potential for edits. I took some original images, added noise to them,
                and then ran the forward process without any conditioning for a variety of starting indices. Here are
                the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/campanile_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/doe_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/moffitt_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Editing Hand-Drawn and Web Images
            </h3>
            <p>
                I decided to try out the same approach above but on nonrealistic images. One of them was downloaded from
                the internet while the other two are hand-drawn images. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/tiger_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/tiger_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/tiger_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/tiger_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/tiger_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/tiger_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/tiger.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/dog_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/dog_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/dog_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/dog_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/dog_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/dog_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/dog.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/watermelon_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/watermelon_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/watermelon_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/watermelon_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/watermelon_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/watermelon_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/watermelon.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Inpainting
            </h3>
            <p>
                I used the same approach above to implement inpainting of images. Given an original image,
                $x_\text{orig}$ and a binary mask $m$, I can generate a new image that that retains the original content
                where $m = 0$, while generating new content in the regions where $m = 1$. I used the following
                expression to get the new image:
                $$x_{t} \leftarrow \mathbf{m}x_{t} + (1 - \mathbf{m})\text{forward}(x_{\text{orig}}, t)$$
                This helps to leave everything within the mask region untouched while only denoising and replacing
                everything outside of it with new content. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Campanile</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_mask.png" align="middle" width="400px" />
                        <figcaption>Mask</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_to_replace.png" align="middle" width="400px" />
                        <figcaption>To Replace</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_inpainted.png" align="middle" width="400px" />
                        <figcaption>Campanile Inpainted</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/doe.png" align="middle" width="400px" />
                        <figcaption>Doe Library</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_library_mask.png" align="middle" width="400px" />
                        <figcaption>Mask</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_to_replace.png" align="middle" width="400px" />
                        <figcaption>To Replace</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_library_inpainted.png" align="middle" width="400px" />
                        <figcaption>Doe Library Inpainted</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/moffitt.png" align="middle" width="400px" />
                        <figcaption>Moffitt Library</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_mask.png" align="middle" width="400px" />
                        <figcaption>Mask</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_to_replace.png" align="middle" width="400px" />
                        <figcaption>To Replace</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_inpainted.png" align="middle" width="400px" />
                        <figcaption>Moffitt Inpainted</figcaption>
                    </td>
                </tr>
            </table>

            <p>
                In the first image, I made it so that the Campanile would look more like a lighthouse. Then I changed
                the Doe Library to look more like an oil painting by replacing the left side with a mountainous
                background. Finally, for Moffitt Library, I replaced the building with a cool looking red shed and a
                nice green scenery.
            </p>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Text-Conditional Image-to-image Translation
            </h3>
            <p>
                Afterwards, I followed the same procedure as above but instead will guide the projection using a text
                prompt. This means that it is no longer a pure "projection to the natural image manifold" anymore but
                also adds control using language. I changed the prompt from <i>a high quality photo</i> to <i>a rocket
                    ship</i> for the Campanile image, <i>an oil painting of a snowy mountain village</i> for the Doe
                Library image, and finally <i>a lithograph of waterfalls</i> for the Moffitt Library image. Here are the
                results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/campanile_rocket_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_rocket_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_rocket_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_rocket_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_rocket_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campanile_rocket_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/SamplingLoops/campanile.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/doe_mountain_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_mountain_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_mountain_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_mountain_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_mountain_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe_mountain_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/doe.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/moffitt_waterfall_1.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=1</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_waterfall_3.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=3</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_waterfall_5.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=5</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_waterfall_7.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=7</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_waterfall_10.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=10</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt_waterfall_20.png" align="middle" width="400px" />
                        <figcaption><code class="highlighter-rouge">i_start=20</code></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/moffitt.png" align="middle" width="400px" />
                        <figcaption>Original</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section VIII: Visual Anagrams</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Visual Anagrams
            </h3>
            <p>
                In this section, I created an image what would look like a certain prompt but when flipped upside down
                it will look like a completely different prompt. To achieve this, I needed to take in two different
                prompts and calculate their respective estimated noise. These were the following equations I used:

                $$
                \begin{align*}
                \epsilon_1 &= \text{UNet}(x_t, t, p_1) \\
                \epsilon_2 &= \text{flip}(\text{UNet}(\text{flip}(x_t), t, p_2)) \\
                \epsilon &= (\epsilon_1 + \epsilon_2) / 2
                \end{align*}
                $$
                By flipping the image and running the UNet on it, I am able to apply a reverse diffusion step to
                generate image on the opposite direction. Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/old_man_campfire.png" align="middle" width="400px" />
                        <figcaption><i>"An Oil Painting of an Old Man"</i></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/campfire_old_man.png" align="middle" width="400px" />
                        <figcaption><i>"An Oil Painting of People Around a Campfire</i></figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/mountain_coast.png" align="middle" width="400px" />
                        <figcaption><i>"An Oil Painting of a Snowy Mountain Village</i></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/coast_mountain.png" align="middle" width="400px" />
                        <figcaption><i>"A Photo of the Amalfi Coast"</i></figcaption>
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/man_dog.png" align="middle" width="400px" />
                        <figcaption><i>"An Photo of a Man"</i></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/dog_man.png" align="middle" width="400px" />
                        <figcaption><i>"A Photo of a Dog"</i></figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section IX: Hybrid Images</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Hybrid Images
            </h3>
            <p>
                In this section, I implemented factorized diffusion to create hybrid images similar to project 2. I
                would take in two different prompts and then passed in the estimated noises into a low-pass filter and a
                high-pass filter. Afterwards, I used this as the final noise estimate. For the low-pass and high-pass
                filters, I simply used a Gaussian filter with a kernel size of 33 and sigma of 2. These were the
                following equations I used:

                $$
                \begin{align*}
                \epsilon_1 &= \text{UNet}(x_t, t, p_1) \\
                \epsilon_2 &= \text{UNet}(x_t, t, p_2) \\
                \epsilon &= f_\text{low pass}(\epsilon_1) + f_\text{high pass}(\epsilon_2)
                \end{align*}
                $$
                Here are the results:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5a/Edits/hybrid_skull_waterfall.png" align="middle" width="400px" />
                        <figcaption><i>"Hybrid of Skull and Waterfall"</i></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/hybrid_mountain_man.png" align="middle" width="400px" />
                        <figcaption><i>"Hybrid of Snowy Mountain and Old Man</i></figcaption>
                    </td>
                    <td>
                        <img src="./Images/5a/Edits/hybrid_skull_dog.png" align="middle" width="400px" />
                        <figcaption><i>"Hybrid of Skull and Dog</i></figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section V: Conclusion</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Learnings
            </h3>
            <p>
                The coolest thing I learned from this project was how to create the estimated noise, sampling loops and then use them to edit the images. I loved using it to do the inpainting and visual anagrams. It was very cool to generate an image from random noise too.
            </p>
        </div>



        <br>
        <br>

        <h1 align="middle"><a href="#5b">Project 5B: Diffusion Models from Scratch</a>
        </h1>

        <div class="bounding-box">

            <h2 align="middle" id="5b">Overview</h2>

            The second part of this project focuses on building diffusion models from scratch to use on the MNIST
            dataset. I implemented a single-step denoising UNet and added time and class conditioning to iteratively
            denoise an image and get better results.
            <br><br>
        </div>

        <br>
        <br>

        <h2 align="middle">Section I: Training a Single-Step Denoising UNet</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Implementing the UNet
            </h3>
            <p>
                In the part A, I had tested out the diffusion model to implement loop sampling, inpainting, and
                hybridization of images. In this part, I implemented a single-step denoising UNet to denoise images. I
                used the following architecture for the UNet:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/architecture/unet.png" align="middle" />
                        <figcaption>UNet Architecture</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5b/architecture/unet_ops.png" align="middle" />
                        <figcaption>Standard Tensor Operations</figcaption>
                    </td>
                </tr>
            </table>
            <br>
            <p>
                I followed along with the standard tensor operations and defined them within the notebook and then used
                the UNet architecture to create the necessary layers with downsampling and upsampling blocks to build
                out skip connections.
            </p>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Using the UNet to Train a Denoiser
            </h3>
            <p>
                In this section, I am trying to solve the following denoising problem: Given a noisy image $z$, I am
                tring to train a denoiser $D_\theta$ such that it can map $z$ to a clean image $x$. I used the following
                loss function to train the denoiser:
                $$ L = \mathbb{E}_{z,x} \|D_{\theta}(z) - x\|^2.$$
                For each training batch, I will generate $z$ with the following process:

                $$ z = x + \sigma \epsilon,\quad \text{where }\epsilon \sim N(0, I)$$
                To train this model, I took the clean images, added noise to them, and then passed them into the UNet
                model. The model would try to return the denoised images. Afterwards, I calculated the MSE loss between
                the denoised images and the original images. By minimizing this loss, I was able to train the model to
                denoise images. The hyperparameters and other architecture that I used were as follows:

            <ul>
                <li>Batch Size: 256</li>
                <li>Hidden Dim: 128</li>
                <li>$\sigma:$ 0.5</li>
                <li>Learning Rate: 1e-4</li>
                <li>Optimizer: Adam</li>
                <li>Epochs: 5</li>
                <li>Loss Function: MSE Loss</li>
            </ul>
            </p>
            <p>
                Here is the visualization of the noising process where $\sigma = [0.0,
                0.2, 0.4, 0.5, 0.6, 0.8, 1.0]$
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/noising_process.png" align="middle" />
                        <figcaption>Noising Processes for Varying $\sigma$</figcaption>
                    </td>
                </tr>
            </table>
            <br>
            <p>
                I had trained the model for 5 epochs over the entire MNIST training dataset. Here is a training loss
                curve plot during the entire process:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/unet_training_loss.png" align="middle" />
                    </td>
                </tr>
            </table>
            <br>

            <p>
                Here are sample results after the 1st and 5th epoch:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/unet_epoch1.png" align="middle" />
                    </td>
                    <td>
                        <img src="./Images/5b/results/unet_epoch5.png" align="middle" />
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Out-of-Distribution Testing
            </h3>
            <p>
                Once the model has been trained, I tested the denoising UNet on noisy samples from the test dataset. I
                kept the same image but varied the noise added to it. Here are the results:
            </p>
            <div align="middle"></div>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/out_of_distribution_testing.png" align="middle" />
                        <figcaption>Denoising Results for Varying $\sigma$</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>

        <h2 align="middle">Section II: Training a Diffusion Model</h2>

        <div class="bounding-box">
            <h3 align="middle">
                Adding Time Conditioning to UNet
            </h3>
            <p>
                In this section, I added time conditioning to the previous UNet model that can iteratively denoise an
                image. The small change to the problem is that now I want to use the UNet to predict the added noise
                $\epsilon$ instead of the clean image $x$. The equation for the loss function is as follows:
                $$L = \mathbb{E}_{\epsilon,z} \|\epsilon_{\theta}(z) - \epsilon\|^2$$.

                To iteratively denoise an image, I needed to generate noisy images $x-t$ from $x_0$ using the following
                equation:

                $$ x_t = \sqrt{\bar\alpha_t} x_0 + \sqrt{1 - \bar\alpha_t} \epsilon
                \quad \text{where}~ \epsilon \sim N(0, 1)$$

                Intuitively, when $t = 0$, I should get back the denoised image while when $t = T$ it should be a pure
                noise image. I also used the DDPM to build the list of $\bar{\alpha}$ values to use for the training
                process.

            <ul>
                <li>
                    $\beta$ is a list of length $T = 300$ equally spaced between 0.0001 and 0.02
                </li>
                <li>
                    $\alpha_t = 1 - \beta_t$
                </li>
                <li>
                    $\bar{\alpha}_t$ is a cumulative product of $\alpha_t$ for $t \in \{1, \cdots, T\}$
                </li>
            </ul>

            I replaced the unflatten and upsample blocks with the following:

            <ul>
                <li>
                    <code>unflatten = unflatten + t1</code>
                </li>
                <li>
                    <code>upsample = upsample + t2</code>
                </li>
            </ul>
            where <code>t1, t2</code> are the results from passing the timestep through the FCBlocks.

            Finally, I conditioned a single UNet on timestep $t$. I used the following architecture for the time
            conditioned UNet:
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/architecture/time_conditioned_unet.png" align="middle" />
                        <figcaption>Time Conditioned UNet Architecture</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5b/architecture/time_conditioned_unet_ops.png" align="middle" />
                        <figcaption>FCBlock</figcaption>
                    </td>
                </tr>
            </table>
            <br>
            <p>
                I followed along with the standard tensor operations and defined them within the notebook and then used
                the UNet architecture to create the necessary layers with downsampling and upsampling blocks to build
                out skip connections. I embedded the time conditioning by normalizing $t$ and adding to the unflatten
                and up sample blocks.
            </p>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Training the UNet
            </h3>
            <p>
                To train this model, I took the clean images, uniformly sampled to create the timesteps $t$, used the
                $\bar{\alpha}$ for the timesteps to get the noisy images, and finally trained with the UNet model. The
                model would try to return the expected noise from the image. Afterwards, I calculated the MSE loss
                between the expected noise and the random pure noise I had generated. By minimizing this loss, I was
                able to train the model to denoise images. The hyperparameters and other architecture that I used were
                as follows:

            <ul>
                <li>Batch Size: 128</li>
                <li>Hidden Dim: 64</li>
                <li>Learning Rate: 1e-3</li>
                <li>Optimizer: Adam</li>
                <li>Scheduler Gamma: $0.1^{(1 / \text{epochs})}$</li>
                <li>Epochs: 20</li>
                <li>Loss Function: MSE Loss</li>
            </ul>
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/architecture/time_conditioned_unet.png" align="middle" />
                        <figcaption>Time Conditioned UNet Architecture</figcaption>
                    </td>
                    <td>
                        <img src="./Images/5b/architecture/time_conditioned_unet_ops.png" align="middle" />
                        <figcaption>FCBlock</figcaption>
                    </td>
                </tr>
            </table>
            <p>
                I had trained directly with the time conditioned UNet by following along with the algorithm below:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/algorithms/time_cond_algo1.png" align="middle" />
                    </td>
                </tr>
            </table>
            <p>
                Here is a training loss
                curve plot during the entire process:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/time_conditioned_training_loss.png" align="middle" />
                    </td>
                </tr>
            </table>
        </div>
        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Sampling from the UNet
            </h3>
            <p>
                I had also sampled directly from the time conditioned UNet by following along with the algorithm below:
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/algorithms/time_cond_algo2.png" align="middle" />
                    </td>
                </tr>
            </table>
            <p>
                Here are some sampling results for the time conditioned UNet model:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/time_conditioned_epoch5.png" align="middle" />
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/time_conditioned_epoch10.png" align="middle" />
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/time_conditioned_epoch15.png" align="middle" />
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/time_conditioned_epoch20.png" align="middle" />
                    </td>
                </tr>
            </table>
        </div>

        <br>

        <div class="bounding-box">
            <h3 align="middle">
                Adding Class-Conditioning to UNet
            </h3>
            <p>
                To improve results and allow for more control over the image generation, I added class conditioning to
                the previous UNet for the digit class 0-9. This included adding 2 more FCBlocks and a one-hot encoded
                vector $c$ for each of the datapoints instead of a single scalar. Since I don't want the model to
                overfit on the classes, I made sure to drop the one-ho
                t encoded vector with a probability of 0.1. I replaced the unflatten and upsample blocks with the
                following:

            <ul>
                <li>
                    <code>unflatten = c1 * unflatten + t1</code>
                </li>
                <li>
                    <code>upsample = c2 * upsample + t2</code>
                </li>
            </ul>
            where <code>c1, c2</code> are the results from passing the one-hot encoded vector through the FCBlocks and
            <code>t1, t2</code> are the results from passing the timestep through the FCBlocks.

            Finally, I conditioned a single UNet on timestep $t$.
            <p>
                I followed along with the standard tensor operations and defined them within the notebook and then used
                the UNet architecture to create the necessary layers with downsampling and upsampling blocks to build
                out skip connections. I embedded the time conditioning by normalizing $t$ and adding to the unflatten
                and up sample blocks and class conditioning by adding the one-hot encoded vector to the unflatten and up
                sample blocks.
            </p>
            <p>
                Compared to the previous time conditioned UNet's training algorithm, the only main difference being the
                addition of the conditioning vector
                $c$
                and periodically performing unconditional generation.
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/algorithms/class_cond_algo1.png" align="middle" />
                    </td>
                </tr>
            </table>

            <p>
                Here is a training loss curve plot during the entire process:
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/class_conditioned_training_loss.png" align="middle" />
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <div class="bounding-box">
            <h3 align="middle">
                Sampling from the Class-Conditioned UNet
            </h3>
            <p>
                I had also sampled directly from the class conditioned UNet by following along with the algorithm below:
            </p>
            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/algorithms/class_cond_algo2.png" align="middle" />
                    </td>
                </tr>
            </table>
            <p>
                Here are some sampling results for the class conditioned UNet model with classifier-free guidance of
                $\gamma = 5.0$:
            </p>

            <table>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/class_conditioned_epoch1.png" align="middle" />
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/class_conditioned_epoch5.png" align="middle" />
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/class_conditioned_epoch10.png" align="middle" />
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/class_conditioned_epoch15.png" align="middle" />
                    </td>
                </tr>
                <tr align="center">
                    <td>
                        <img src="./Images/5b/results/class_conditioned_epoch20.png" align="middle" />
                    </td>
                </tr>
            </table>
        </div>

        <br>
        <br>
        <h2 align="middle">Section III: Conclusion</h2>
        <div class="bounding-box">
            <h3 align="middle">
                Learnings
            </h3>
            <p>
                The coolest thing I learned from this project was how to build my own diffusion model with each of the components and how to connect them properly. I learned the importance of having correct tensor shapes so that the model can properly train on the images. 
            </p>
        </div>

</body>

</html>